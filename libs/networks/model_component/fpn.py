import os,sys 
sys.path.append('.')
import torch.nn as nn
import torch.nn.functional as F

from libs.networks.network_utils.utils import SamePad2d


class FPN(nn.Module):
    def __init__(self, C1, C2, C3, C4, C5, out_channels):
        super(FPN, self).__init__()
        self.out_channels = out_channels
        self.C1 = C1
        self.C2 = C2
        self.C3 = C3
        self.C4 = C4
        self.C5 = C5
        self.P6 = nn.MaxPool2d(kernel_size=1, stride=2)
        self.P5_conv1 = nn.Conv2d(2048, self.out_channels, kernel_size=1,
                                  stride=1)
        self.P5_conv2 = nn.Sequential(
            SamePad2d(kernel_size=3, stride=1),
            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3,
                      stride=1),
        )
        self.P4_conv1 = nn.Conv2d(1024, self.out_channels, kernel_size=1,
                                  stride=1)
        self.P4_conv2 = nn.Sequential(
            SamePad2d(kernel_size=3, stride=1),
            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3,
                      stride=1),
        )
        self.P3_conv1 = nn.Conv2d(512, self.out_channels, kernel_size=1,
                                  stride=1)
        self.P3_conv2 = nn.Sequential(
            SamePad2d(kernel_size=3, stride=1),
            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3,
                      stride=1),
        )
        self.P2_conv1 = nn.Conv2d(256, self.out_channels, kernel_size=1,
                                  stride=1)
        self.P2_conv2 = nn.Sequential(
            SamePad2d(kernel_size=3, stride=1),
            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3,
                      stride=1),
        )

    def forward(self, x):
        x = self.C1(x)
        c2_out = self.C2(x)
        c3_out = self.C3(c2_out)
        c4_out = self.C4(c3_out)
        c5_out = self.C5(c4_out)
        p5_out = self.P5_conv1(c5_out)
        p4_out = self.P4_conv1(c4_out) + F.interpolate(p5_out, scale_factor=2)
        p3_out = self.P3_conv1(c3_out) + F.interpolate(p4_out, scale_factor=2)
        p2_out = self.P2_conv1(c2_out) + F.interpolate(p3_out, scale_factor=2)

        p5_out = self.P5_conv2(p5_out)
        p4_out = self.P4_conv2(p4_out)
        p3_out = self.P3_conv2(p3_out)
        p2_out = self.P2_conv2(p2_out)

        # P6 is used for the 5th anchor scale in RPN. Generated by
        # subsampling from P5 with stride of 2.
        p6_out = self.P6(p5_out)

        # the return feature_map have shape as below: 256 is the self.out_channels
        # p2_out : B x 256 x H/4 x W/4
        # p3_out : B x 256 x H/8 x W/8
        # p4_out : B x 256 x H/16 x W/16
        # p5_out : B x 256 x H/32 x W/32
        # p6_out : B x 256 x H/64 x W/64
        return [p2_out, p3_out, p4_out, p5_out, p6_out]



if __name__ == "__main__":
    from libs.networks.network_utils.resnet import ResNet 
    import torch
    import torch.nn.functional as F 

    resnet = ResNet(architecture="resnet34", stage5=True)

    C1, C2, C3, C4, C5 = resnet.stages()

    # Top-down Layers
    fpn = FPN(C1, C2, C3, C4, C5, out_channels=256)

    images = torch.randn((4,3,540,720))
    images = F.pad(images, (8,8,2,2))
    print(images.size())
    output = fpn(images)
    for out in output:
        print(out.size())
        # torch.Size([4, 256, 136, 184])
        # torch.Size([4, 256, 68, 92])
        # torch.Size([4, 256, 34, 46])
        # torch.Size([4, 256, 17, 23])
        # torch.Size([4, 256, 9, 12])
